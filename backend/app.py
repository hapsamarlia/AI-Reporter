from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from pydub import AudioSegment
import speech_recognition as sr
import subprocess
import ollama  # for llama model response generation

app = Flask(__name__)
CORS(app)

# ‚úÖ Set up FFmpeg path manually
AudioSegment.converter = r"C:\ffmpeg\bin\ffmpeg.exe"
AudioSegment.ffmpeg = r"C:\ffmpeg\bin\ffmpeg.exe"
AudioSegment.ffprobe = r"C:\ffmpeg\bin\ffprobe.exe"

# Folder to save uploaded files
UPLOAD_FOLDER = "uploads"
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)


# üéôÔ∏è Function: Convert + Transcribe Audio
def transcribe_audio(audio_path):
    print("üéß Converting MP3 to WAV using FFmpeg...")
    wav_path = os.path.splitext(audio_path)[0] + ".wav"
    AudioSegment.from_file(audio_path).export(wav_path, format="wav")

    recognizer = sr.Recognizer()
    with sr.AudioFile(wav_path) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data)
            print("üó£Ô∏è Transcription:", text)
            return text
        except sr.UnknownValueError:
            print("‚ö†Ô∏è Speech not clear.")
            return "Could not understand the audio clearly."
        except sr.RequestError as e:
            print("‚ö†Ô∏è Speech Recognition error:", e)
            return f"Speech Recognition error: {e}"


# üß† Function: Generate AI Report using LLaMA (Ollama)
def generate_report(transcription):
    print("üß† Generating business report with LLaMA...")
    try:
        response = ollama.chat(model="llama3.2:1b", messages=[
            {"role": "user", "content": f"Create a short business analysis report for: {transcription}"}
        ])
        result = response["message"]["content"]
        print("üìä Report:", result)
        return result
    except Exception as e:
        print("‚ö†Ô∏è LLaMA error:", e)
        return f"Error generating report: {e}"


# üåç Function: Translate report to French (Offline fallback)
def translate_text(text, lang="fr"):
    print("üåç Translating report to French...")
    try:
        # simple offline translation fallback using ollama
        response = ollama.chat(model="llama3.2:1b", messages=[
            {"role": "user", "content": f"Translate this text to French:\n{text}"}
        ])
        result = response["message"]["content"]
        print("‚úÖ Translated Report:", result)
        return result
    except Exception as e:
        print("‚ö†Ô∏è Translation error:", e)
        return f"Error translating text: {e}"


# üöÄ Route: Handle audio upload + full processing
@app.route("/analyze_audio", methods=["POST"])
def analyze_audio():
    if "file" not in request.files:
        return jsonify({"error": "No file uploaded"}), 400

    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "Empty filename"}), 400

    file_path = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(file_path)

    print(f"\nüìÅ Received file: {file.filename}")
    print("------------------------------------------")

    # Step 1: Transcription
    transcription = transcribe_audio(file_path)
    # Step 2: Report Generation
    report = generate_report(transcription)
    # Step 3: Translation
    translated = translate_text(report, "fr")

    print("------------------------------------------")
    print("‚úÖ Process completed.\n")

    return jsonify({
        "transcription": transcription,
        "report": report,
        "translated_report": translated
    })


if __name__ == "__main__":
    app.run(debug=True)
